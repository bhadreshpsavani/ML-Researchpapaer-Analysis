# ML-Researchpapaer-Analysis:

* [RoFormer](https://arxiv.org/pdf/2104.09864v1.pdf): Gives better performance when long text sequence
* [UnifiedQA](https://arxiv.org/abs/2005.00700): A single model that works on various kinf of QA tasks 
* [MPNET](https://arxiv.org/pdf/2004.09297.pdf)
* [SPECTER](https://arxiv.org/pdf/2004.07180.pdf)
* [TLDR](https://arxiv.org/pdf/2004.15011.pdf)
* [Movement Pruning: Adaptive Sparsity by Fine-Tuning](https://arxiv.org/pdf/2005.07683.pdf)

Notes: 
* Movement pruning, a simple, deterministic first-order weight pruning method that is more adaptive to pretrained model fine-tuning.
* Sparsity induction is a widely used approach to reduce the memory footprint of neural networks atonly a small cost of accuracy. 
* Pruning methods, which remove weights based on their importance,are a particularly simple and effective method for compressing models.
* movement pruning, i.e., pruning approaches that consider the changes in weights duringfine-tuning. Movement pruning differs from magnitude pruning in that both weights with low and high values can be pruned if they shrink during training
